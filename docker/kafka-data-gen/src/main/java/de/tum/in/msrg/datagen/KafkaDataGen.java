package de.tum.in.msrg.datagen;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import de.tum.in.msrg.common.PageTSKey;
import de.tum.in.msrg.datamodel.ClickEvent;
import de.tum.in.msrg.datamodel.UpdateEvent;
import io.prometheus.client.Counter;
import io.prometheus.client.exporter.HTTPServer;
import org.apache.commons.cli.*;
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.ByteArraySerializer;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;

import java.io.IOException;
import java.time.Duration;
import java.time.Instant;
import java.time.temporal.ChronoUnit;
import java.util.*;

/**
 * Hello world!
 *
 */
public class KafkaDataGen
{
    public static final Duration WINDOW_SIZE = Duration.of(60, ChronoUnit.SECONDS );
    public static final List<String> PAGES = Arrays.asList("/help", "/index", "/shop", "/jobs", "/about", "/news");
    public static final List<String> SHORT_PAGES = Arrays.asList("/jobs", "/about", "/news");


    private final String bootstrap;
    private final long delay;
    private final long delayLength;
    private final int eventsPerWindow;
    private final List<String> pages;
    private final Map<PageTSKey, Date> inputTimeMap;
    private final Map<PageTSKey, List<Long>> inputIdMap;
    private final Long benchmarkLength;


    private final ObjectMapper objectMapper = new ObjectMapper();

    private static final Logger LOGGER = LogManager.getLogger(KafkaDataGen.class);


    public KafkaDataGen(
            Long benchmarkLength,
            String bootstrap,
            long delay,
            long delayLength,
            int eventsPerWindow,
            Map<PageTSKey, Date> inputTimeMap,
            Map<PageTSKey, List<Long>> inputIdMap) throws IOException {

        this.benchmarkLength = benchmarkLength;
        this.bootstrap = bootstrap;
        this.delay = delay;
        this.delayLength = delayLength;
        this.eventsPerWindow = eventsPerWindow;
        this.pages = PAGES;
        this.inputTimeMap = inputTimeMap;
        this.inputIdMap = inputIdMap;
    }

    public void start() throws JsonProcessingException, InterruptedException {
        LOGGER.info("Creating counters...");
        Counter recordsCounter = Counter.build(
                "de_tum_in_msrg_datagen_records_total",
                "Total number of messages generated by the generator")
                .labelNames("key").register();

        Counter expectedCounter = Counter.build(
                "de_tum_in_msrg_pgv_expected_windows",
                "Expected windows")
                .labelNames("key").register();

        ClickIterator clickIterator = new ClickIterator(this.eventsPerWindow, this.pages);

        long counter = 0L;
        // Update the pages half way the window
        long nextUpdate = (WINDOW_SIZE.toMillis() / 2);

        try (KafkaProducer<byte [], byte []> kafkaProducer = new KafkaProducer<byte[], byte[]>(getKafkaProps(bootstrap, delay))) {


//        kafkaProducer.initTransactions();
//        kafkaProducer.beginTransaction();
            LOGGER.info("Producing records...");
            Instant benchmarkEndTime = Instant.now().plusSeconds(benchmarkLength);
            LOGGER.info(benchmarkEndTime.toString());

            while (benchmarkEndTime.isAfter(Instant.now())) {
                LOGGER.debug(Instant.now().toString());

                ClickEvent clickEvent = clickIterator.next();
                if (clickEvent.getTimestamp().getTime() > nextUpdate) {
                    updatePages(clickEvent, kafkaProducer, objectMapper, clickIterator);
                    nextUpdate += WINDOW_SIZE.toMillis();
                    clickEvent.setId(clickIterator.id);
                }


                ProducerRecord<byte[], byte[]> record = new ProducerRecord<>(
                        "click",
                        this.objectMapper.writeValueAsBytes(clickEvent.getPage()),
                        this.objectMapper.writeValueAsBytes(clickEvent));

                kafkaProducer.send(record, new SendCallback(clickEvent, inputTimeMap, inputIdMap, recordsCounter, expectedCounter));
                counter++;


//                recordsCounter.labels(clickEvent.getPage()).inc();

                if (counter == this.delay) {
                    Thread.sleep(delayLength);
                    counter = 0;
                    kafkaProducer.flush();
//                this.kafkaProducer.commitTransaction();
//                kafkaProducer.beginTransaction();
                }
            }
        }
    }


    public static void main( String[] args ) throws InterruptedException, ParseException, IOException {

        Options cliOptns = KafkaDataGen.createCLI();
        DefaultParser parser = new DefaultParser();
        CommandLine cmdLine = parser.parse(cliOptns, args);

        String bootstrap = cmdLine.getOptionValue("kafka", "kafka:9092");
        LOGGER.info(String.format("Kafka bootstrap server: %s", bootstrap));
//        String topic = cmdLine.getOptionValue("topic","input");
        long delay = Long.parseLong(cmdLine.getOptionValue("delay", "1000"));
        LOGGER.info(String.format("Thread sleep after %d records", delay));

        long delayLength = Long.parseLong(cmdLine.getOptionValue("length", "1"));
        LOGGER.info(String.format("Thread sleep for %d ms", delayLength));

        int eventsPerWindow = Integer.parseInt(cmdLine.getOptionValue("events", "5000"));
        LOGGER.info(String.format("Events per window: %d", eventsPerWindow));

        boolean shortPagesFlag = cmdLine.hasOption("short");
        List<String> pages = null;
        if (shortPagesFlag){
            pages = SHORT_PAGES;
        } else {
            pages = PAGES;
        }

//        HTTPServer promServer = new HTTPServer(52923);
//        KafkaProducer<byte[], byte[]> kafkaProducer = new KafkaProducer<byte[], byte[]>(getKafkaProps(bootstrap, delay));

//        KafkaDataGen dataGen = new KafkaDataGen(bootstrap, delay, delayLength, eventsPerWindow, pages, promServer);

//        Runtime.getRuntime().addShutdownHook( new Thread(() -> {
//            try {
//                Thread.sleep(15000);
//                kafkaProducer.abortTransaction();
//                kafkaProducer.close();
//
//                LOGGER.info(promServer.getPort());
//                promServer.close();
//                LOGGER.info(promServer.getPort());
//
//            } catch (InterruptedException e) {
//                e.printStackTrace();
//            }
//        }));

//        dataGen.start();

        }


    protected static Options createCLI() {
        Options options = new Options();

        Option kafkaOptn = Option.builder("kafka")
                .argName("bootstrap")
                .hasArg()
                .desc("Kafka bootstrap server")
                .build();

        Option epwOptn = Option.builder("events")
                .argName("eventsPerWindow")
                .hasArg()
                .desc("Events per window")
                .build();

        Option delayOptn = Option.builder("delay")
                .argName("count")
                .hasArg()
                .desc("Insert delay after count events")
                .build();

        Option delayLengthOptn = Option.builder("length")
                .argName("delayLength")
                .hasArg()
                .desc("Length of delay after count events [ms]")
                .build();

        Option pagesFlag = Option.builder("short")
                .hasArg(false)
                .desc("if we should use short pages")
                .build();


        options.addOption(kafkaOptn);
        options.addOption(epwOptn);
        options.addOption(delayOptn);
        options.addOption(delayLengthOptn);
        options.addOption(pagesFlag);


        return options;
    }
    protected void updatePages(ClickEvent clickEvent, KafkaProducer<byte[], byte[]> kafkaProducer, ObjectMapper objectMapper, ClickIterator clickIterator) throws JsonProcessingException {
        for (String page : this.pages){
            UpdateEvent updateEvent = new UpdateEvent(clickIterator.id, clickEvent.getTimestamp(), page, "");
            ProducerRecord<byte[], byte[]> producerRecord = new ProducerRecord<>("update", objectMapper.writeValueAsBytes(updateEvent.getPage()), objectMapper.writeValueAsBytes(updateEvent));
            kafkaProducer.send(producerRecord);
            clickIterator.id++;
        }
    }

    protected static Properties getKafkaProps(String bootstrap, long delay){
        Properties props = new Properties();

        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrap);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getCanonicalName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getCanonicalName());
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, (int)delay);
        props.put(ProducerConfig.LINGER_MS_CONFIG, 100);
//        props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, "datagen");


        return props;
    }
    static class ClickIterator  {

        private Map<String, Long> nextTimestampPerKey;
        private int nextPageIndex;
        protected long id = 0L;
        protected int eventPerWindow;
        protected List<String> pages;

        ClickIterator() {
            nextTimestampPerKey = new HashMap<>();
            nextPageIndex = 0;
            this.eventPerWindow = 5000;
        }

        ClickIterator(int eventsPerWindow, List<String> pages){
            nextTimestampPerKey = new HashMap<>();
            nextPageIndex = 0;
            this.eventPerWindow = eventsPerWindow;
            this.pages = pages;
        }

        ClickEvent next() {
            String page = nextPage();
            id++;
            if (id == Long.MAX_VALUE) {
                id = Long.MIN_VALUE;
            }
            return new ClickEvent(id, nextTimestamp(page), page);
        }

        private Date nextTimestamp(String page) {
            long nextTimestamp = nextTimestampPerKey.getOrDefault(page, 1L);
//			nextTimestampPerKey.put(page, nextTimestamp + WINDOW_SIZE.toMilliseconds() / EVENTS_PER_WINDOW);
            nextTimestampPerKey.put(page, nextTimestamp + (WINDOW_SIZE.toMillis()  / this.eventPerWindow ) );
            return new Date(nextTimestamp);
        }

        private String nextPage() {
            String nextPage = this.pages.get(nextPageIndex);
            if (nextPageIndex == this.pages.size() - 1) {
                nextPageIndex = 0;
            } else {
                nextPageIndex++;
            }
            return nextPage;
        }
    }

    static class UpdateIterator {
        private long lastUpdated = 30000L;
    }
}
