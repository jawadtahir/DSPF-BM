package de.tum.in.msrg.datagen;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import de.tum.in.msrg.datamodel.ClickEvent;
import de.tum.in.msrg.datamodel.UpdateEvent;
import io.prometheus.client.Counter;
import io.prometheus.client.exporter.HTTPServer;
import org.apache.commons.cli.*;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.ByteArraySerializer;
import org.apache.kafka.common.serialization.StringSerializer;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;

import java.io.BufferedWriter;
import java.io.FileWriter;
import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.time.Duration;
import java.time.Instant;
import java.time.temporal.ChronoUnit;
import java.util.*;

/**
 * Hello world!
 *
 */
public class KafkaDataGen
{
    public static final Duration WINDOW_SIZE = Duration.of(60, ChronoUnit.SECONDS );
    private static final List<String> pages = Arrays.asList("/help", "/index", "/shop", "/jobs", "/about", "/news");


    private final String bootstrap;
    private final long delay;
    private final long delayLength;
    private final int eventsPerWindow;

    private final HTTPServer promServer;
    private final KafkaProducer<byte[], byte[]> kafkaProducer;

    private final ObjectMapper objectMapper = new ObjectMapper();

    private static final Logger LOGGER = LogManager.getLogger(KafkaDataGen.class);


    public KafkaDataGen(String bootstrap, long delay, long delayLength, int eventsPerWindow, HTTPServer promServer, KafkaProducer<byte[], byte[]> kafkaProducer) throws IOException {
        this.bootstrap = bootstrap;
        this.delay = delay;
        this.delayLength = delayLength;
        this.eventsPerWindow = eventsPerWindow;
        this.promServer = promServer;
        this.kafkaProducer = kafkaProducer;
    }

    protected void start() throws JsonProcessingException, InterruptedException {
        LOGGER.info("Creating counters...");
        Counter recordsCounter = Counter.build(
                "de_tum_in_msrg_datagen_records_total",
                "Total number of messages generated by the generator")
                .labelNames("key").register();
        Counter idRolloverCounter = Counter.build(
                "de_tum_in_msrg_datagen_id_rollover_total",
                "Total number of times ID roll overed")
                .register();

        ClickIterator clickIterator = new ClickIterator(this.eventsPerWindow);

        long counter = 0L;
        // Update the pages half way the window
        long nextUpdate = (WINDOW_SIZE.toMillis() / 2);

        LOGGER.info("Producing records...");
        while (true) {
            ClickEvent clickEvent = clickIterator.next();
            if (clickEvent.getTimestamp().getTime() > nextUpdate) {
                updatePages(clickEvent, kafkaProducer, objectMapper, clickIterator);
                nextUpdate += WINDOW_SIZE.toMillis();
                clickEvent.setId(clickIterator.id);
            }


            ProducerRecord<byte[], byte[]> record = new ProducerRecord<>(
                    "click",
                    this.objectMapper.writeValueAsBytes(clickEvent.getPage()),
                    this.objectMapper.writeValueAsBytes(clickEvent));

            kafkaProducer.send(record);
            counter++;


            recordsCounter.labels(clickEvent.getPage()).inc();
            if (clickEvent.getId() == Long.MIN_VALUE) {
                idRolloverCounter.inc();
            }

            if (counter == this.delay) {
                Thread.sleep(delayLength);
                counter = 0;
                this.kafkaProducer.flush();
            }
        }
    }


    public static void main( String[] args ) throws InterruptedException, ParseException, IOException {

        Options cliOptns = KafkaDataGen.createCLI();
        DefaultParser parser = new DefaultParser();
        CommandLine cmdLine = parser.parse(cliOptns, args);

        String bootstrap = cmdLine.getOptionValue("kafka", "kafka:9092");
        LOGGER.info(String.format("Kafka bootstrap server: %s", bootstrap));
//        String topic = cmdLine.getOptionValue("topic","input");
        long delay = Long.parseLong(cmdLine.getOptionValue("delay", "1000"));
        LOGGER.info(String.format("Thread sleep after %d records", delay));

        long delayLength = Long.parseLong(cmdLine.getOptionValue("length", "1"));
        LOGGER.info(String.format("Thread sleep for %d ms", delayLength));

        int eventsPerWindow = Integer.parseInt(cmdLine.getOptionValue("events", "5000"));
        LOGGER.info(String.format("Events per window: %d", eventsPerWindow));

        HTTPServer promServer = new HTTPServer(52923);
        KafkaProducer<byte[], byte[]> kafkaProducer = new KafkaProducer<byte[], byte[]>(getKafkaProps(bootstrap));

        KafkaDataGen dataGen = new KafkaDataGen(bootstrap, delay, delayLength, eventsPerWindow, promServer, kafkaProducer);

        Runtime.getRuntime().addShutdownHook( new Thread(() -> {
            try {
                kafkaProducer.flush();
                kafkaProducer.close();
                Thread.sleep(15000);
                LOGGER.info(promServer.getPort());
                promServer.close();
                LOGGER.info(promServer.getPort());

            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }));

//        Path rootReportFolder = Paths.get("/reports", Instant.now().toString());
//        Path createdDir = Files.createDirectories(rootReportFolder);
//        FileWriter fileWriter = new FileWriter(createdDir.resolve("datagen.txt").toFile(), false);


        dataGen.start();






        }


    protected static Options createCLI() {
        Options options = new Options();

        Option kafkaOptn = Option.builder("kafka")
                .argName("bootstrap")
                .hasArg()
                .desc("Kafka bootstrap server")
                .build();

        Option epwOptn = Option.builder("events")
                .argName("eventsPerWindow")
                .hasArg()
                .desc("Events per window")
                .build();

        Option delayOptn = Option.builder("delay")
                .argName("count")
                .hasArg()
                .desc("Insert delay after count events")
                .build();

        Option delayLengthOptn = Option.builder("length")
                .argName("delayLength")
                .hasArg()
                .desc("Length of delay after count events [ms]")
                .build();


        options.addOption(kafkaOptn);
        options.addOption(epwOptn);
        options.addOption(delayOptn);
        options.addOption(delayLengthOptn);


        return options;
    }
    protected void updatePages(ClickEvent clickEvent, KafkaProducer<byte[], byte[]> kafkaProducer, ObjectMapper objectMapper, ClickIterator clickIterator) throws JsonProcessingException {
        for (String page : pages){
            UpdateEvent updateEvent = new UpdateEvent(clickIterator.id, clickEvent.getTimestamp(), page, "");
            ProducerRecord<byte[], byte[]> producerRecord = new ProducerRecord<>("update", objectMapper.writeValueAsBytes(updateEvent.getPage()), objectMapper.writeValueAsBytes(updateEvent));
            kafkaProducer.send(producerRecord);
            clickIterator.id++;
        }
    }

    protected static Properties getKafkaProps(String bootstrap){
        Properties props = new Properties();

        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrap);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getCanonicalName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getCanonicalName());


        return props;
    }
    static class ClickIterator  {

        private Map<String, Long> nextTimestampPerKey;
        private int nextPageIndex;
        protected long id = 0L;
        protected int eventPerWindow;

        ClickIterator() {
            nextTimestampPerKey = new HashMap<>();
            nextPageIndex = 0;
            this.eventPerWindow = 5000;
        }

        ClickIterator(int eventsPerWindow){
            nextTimestampPerKey = new HashMap<>();
            nextPageIndex = 0;
            this.eventPerWindow = eventsPerWindow;
        }

        ClickEvent next() {
            String page = nextPage();
            id++;
            if (id == Long.MAX_VALUE) {
                id = Long.MIN_VALUE;
            }
            return new ClickEvent(id, nextTimestamp(page), page);
        }

        private Date nextTimestamp(String page) {
            long nextTimestamp = nextTimestampPerKey.getOrDefault(page, 1L);
//			nextTimestampPerKey.put(page, nextTimestamp + WINDOW_SIZE.toMilliseconds() / EVENTS_PER_WINDOW);
            nextTimestampPerKey.put(page, nextTimestamp + (WINDOW_SIZE.toMillis()  / this.eventPerWindow ) );
            return new Date(nextTimestamp);
        }

        private String nextPage() {
            String nextPage = pages.get(nextPageIndex);
            if (nextPageIndex == pages.size() - 1) {
                nextPageIndex = 0;
            } else {
                nextPageIndex++;
            }
            return nextPage;
        }
    }

    static class UpdateIterator {
        private long lastUpdated = 30000L;
    }
}
